name: experiment                            # name of the config. DOES NOT HAVE SPACE ON IT
upscale_factor: 3                           # upscale_factor can be 2, 3 or 4


# model options
model:
    hidden_channels_1: 64                   # number of filters in output of the frist Conv2d layer 
    hidden_channels_2: 32                   # number of filters in output of the second Conv2d layer
    # dropout: 0                            # dropout probability
    loss: MSE                               # loss function
    optimizer: adam                         # optimizer function
    learning_rate: 0.001                    # learning rate
    # activation_function: tanh             # activation function
    # output_activation_function: sigmoid   # output activation function
    data_normalisation: true                # if true, input:image/255 and predict:output*255


# data options
data:
    path: data\patches
    image_size: 240,240

# train options
train:
    path:
        HR: DIV2K_train_HR             # path to the train HR data
        X2: DIV2K_train_LR_bicubic\X2  # path to the train x2 data
        X3: DIV2K_train_LR_bicubic\X3  # path to the train x3 data
        X4: DIV2K_train_LR_bicubic\X4  # path to the train x4 data

    epochs: 30                              # number of epochs
    batch_size: 64                          # training batch size
    # virtual_batch_size: 16                # size of the virtual batch
    save_learning_curves: true              # save the learning curves
    logs_path: logs                         # path to logs folder
    save_checkpoint: all                    # if you want save the models weight: all, last, best or false
    shuffle: true                           # shuffle the data at each epoch
    drop_last: false                        # drop the last batch if there dont have a complete batch


# validation options
val:
    path:
        HR: DIV2K_valid_HR             # path to the valid HR data
        X2: DIV2K_valid_LR_bicubic\X2  # path to the valid x2 data
        X3: DIV2K_valid_LR_bicubic\X3  # path to the valid x3 data
        X4: DIV2K_valid_LR_bicubic\X4  # path to the valid x4 data

    batch_size: 64                          # validation batch size
    shuffle: true                           # shuffle the data at each epoch
    drop_last: false                        # drop the last batch if there dont have a complete batch
